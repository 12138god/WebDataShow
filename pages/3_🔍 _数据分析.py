# _*_ coding :utf-8 _*_
# @Time : 2024/3/13 4:58
# @Author ï¼šææ–‡æ°
import pandas as pd
import streamlit as st
from sqlalchemy import create_engine, text
import plotly.express as px
import folium
from folium.plugins import HeatMap
import streamlit.components.v1 as components
import plotly.graph_objects as go

# æ•°æ®åº“è¿æ¥é…ç½®
DATABASE_URI = 'mysql+pymysql://root:198881@localhost/AnalysisDB'
engine = create_engine(DATABASE_URI)

# é¡µé¢å¸ƒå±€
st.set_page_config(
    page_title="æ•°æ®åˆ†æ",
    page_icon="ğŸ”",
)

@st.cache_data
def get_provinces():
    query = """
    SELECT DISTINCT Province
    FROM WeiboArticles
    WHERE Province IS NOT NULL AND Province != ''
    ORDER BY Province;
    """
    provinces = pd.read_sql_query(query, engine)['Province'].tolist()
    return ['å…¨éƒ¨'] + provinces

# æ•°æ®æºå¯¹æ¯”
with st.container():
    st.title("æ•°æ®æºå¯¹æ¯”")
    # ä»æ•°æ®åº“æŸ¥è¯¢æ•°æ®
    @st.cache_data
    def get_data_source_comparison():
        query = """
        SELECT DataSource, Category, COUNT(*) AS ArticleCount
        FROM Topics
        JOIN GovernmentArticleTopicAssociation ON Topics.TopicID = GovernmentArticleTopicAssociation.TopicID
        GROUP BY DataSource, Category
        UNION ALL
        SELECT 'Toutiao' AS DataSource, Category, COUNT(*) AS ArticleCount
        FROM Topics
        JOIN ToutiaoArticleTopicAssociation ON Topics.TopicID = ToutiaoArticleTopicAssociation.TopicID
        GROUP BY DataSource, Category
        UNION ALL
        SELECT 'Weibo' AS DataSource, Category, COUNT(*) AS ArticleCount
        FROM Topics
        JOIN WeiboArticleTopicAssociation ON Topics.TopicID = WeiboArticleTopicAssociation.TopicID
        GROUP BY DataSource, Category;
        """
        return pd.read_sql_query(query, engine)


    df = get_data_source_comparison()

    # è·å–å”¯ä¸€çš„æ•°æ®æºåˆ—è¡¨

    data_sources = df['DataSource'].unique()

    # åˆ›å»ºä¸‰åˆ—ç”¨äºå¹¶æ’æ˜¾ç¤ºå›¾è¡¨
    st.markdown("### ä¸åŒæ•°æ®æºä¸»é¢˜å…³æ³¨åº¦å¯¹æ¯”")
    col1, col2, col3 = st.columns(3)

    # åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå°†æ•°æ®æºä¸å¯¹åº”çš„Streamlitåˆ—å…³è”èµ·æ¥

    columns = {data_sources[i]: col for i, col in enumerate([col1, col2, col3])}

    for source in data_sources:
        # æ ¹æ®å½“å‰æ•°æ®æºç­›é€‰æ•°æ®
        df_source = df[df['DataSource'] == source]

        # è½¬æ¢æ•°æ®ä¸ºé›·è¾¾å›¾æ‰€éœ€æ ¼å¼
        categories = df_source['Category'].tolist()
        values = df_source['ArticleCount'].tolist()

        # é›·è¾¾å›¾éœ€è¦é—­ç¯ï¼Œå› æ­¤åœ¨æœ«å°¾æ·»åŠ ç¬¬ä¸€ä¸ªå€¼æ¥é—­åˆå›¾å½¢
        categories += [categories[0]]
        values += [values[0]]

        # åˆ›å»ºé›·è¾¾å›¾

        fig_radar = go.Figure()

        fig_radar.add_trace(go.Scatterpolar(
            r=values,
            theta=categories,
            fill='toself',
            name=source
        ))

        # æ›´æ–°é›·è¾¾å›¾çš„å¸ƒå±€
        fig_radar.update_layout(
            width=300,  # è®¾ç½®å®½åº¦
            height=300,  # è®¾ç½®é«˜åº¦
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, max(values)]  # æ ¹æ®ä½ çš„æ•°æ®èŒƒå›´è°ƒæ•´
                )),
            showlegend=False,
            title=f"{source} ä¸»é¢˜å…³æ³¨åº¦å¯¹æ¯”"
        )

        # åœ¨å¯¹åº”çš„åˆ—ä¸­æ˜¾ç¤ºå›¾è¡¨
        columns[source].plotly_chart(fig_radar, use_container_width=True)

    fig_heatmap = px.density_heatmap(df, x="DataSource", y="Category", z="ArticleCount", marginal_x="rug",
                                     marginal_y="histogram")
    st.markdown("### æ•°æ®æºä¸ä¸»é¢˜ç±»åˆ«é—´çš„æ–‡ç« åˆ†å¸ƒçƒ­åŠ›å›¾")
    st.plotly_chart(fig_heatmap, use_container_width=True)

    fig_parallel = px.parallel_categories(df, dimensions=['DataSource', 'Category', 'ArticleCount'],
                                          color="ArticleCount", color_continuous_scale=px.colors.sequential.Inferno)
    st.header("ä¸åŒæ•°æ®æºä¸­ä¸»é¢˜ç±»åˆ«çš„æ–‡ç« æ•°é‡å¹³è¡Œåæ ‡å›¾")
    st.plotly_chart(fig_parallel, use_container_width=True)

st.markdown("---")


# ä½¿ç”¨containerå®¹å™¨ç»„ç»‡ä¸»é¢˜è¶‹åŠ¿åˆ†æéƒ¨åˆ†
@st.cache_data
def get_distinct_categories():
    query = "SELECT DISTINCT Category FROM Topics"
    with engine.connect() as conn:
        result = conn.execute(text(query))
        categories = [row['Category'] for row in result.mappings()]
    return categories


@st.cache_data
def get_distinct_labels(category=None):
    if category and category != 'å…¨éƒ¨':
        query = "SELECT DISTINCT Label FROM Topics WHERE Category = :category"
        with engine.connect() as conn:
            result = conn.execute(text(query), {'category': category})
            labels = [row['Label'] for row in result.mappings()]
    else:
        query = "SELECT DISTINCT Label FROM Topics"
        with engine.connect() as conn:
            result = conn.execute(text(query))
            labels = [row['Label'] for row in result.mappings()]
    return labels


@st.cache_data
def get_document_count_by_period_and_source(category, label, data_sources):
    where_conditions = []
    if category != 'å…¨éƒ¨':
        where_conditions.append(f"t.Category = '{category}'")
    if label != 'å…¨éƒ¨':
        where_conditions.append(f"t.Label = '{label}'")

    union_queries = []
    for source in data_sources:
        table_name = f"{source}Articles"
        assoc_table_name = f"{source}ArticleTopicAssociation"
        union_query = f"""
        SELECT '{source}' AS Source, YEAR(a.PubDate) AS Year, 
               CASE WHEN MONTH(a.PubDate) <= 6 THEN 'H1' ELSE 'H2' END AS Half, 
               COUNT(*) AS DocumentCount
        FROM {table_name} a
        JOIN {assoc_table_name} ata ON a.ArticleID = ata.ArticleID
        JOIN Topics t ON ata.TopicID = t.TopicID
        """
        if where_conditions:
            union_query += "WHERE " + " AND ".join(where_conditions) + " \n"
        union_query += "GROUP BY Source, Year, Half"
        union_queries.append(union_query)

    if union_queries:
        query = "\nUNION ALL\n".join(union_queries)
        query += "\nORDER BY Year, Half, Source;"
        with engine.connect() as conn:
            df = pd.read_sql_query(text(query), conn)
        return df
    else:
        return pd.DataFrame()


with st.container():
    st.header("ä¸»é¢˜è¶‹åŠ¿åˆ†æ")

    # ä½¿ç”¨columnså¸ƒå±€ä¼˜åŒ–ç­›é€‰å™¨å¸ƒå±€
    col1, col2, col3 = st.columns(3)
    with col1:
        categories = ['å…¨éƒ¨'] + get_distinct_categories()
        selected_category = st.selectbox("é€‰æ‹©ä¸»é¢˜ç±»åˆ«", categories)

    with col2:
        labels = ['å…¨éƒ¨'] + get_distinct_labels(selected_category)
        selected_label = st.selectbox("é€‰æ‹©ä¸»é¢˜", labels)

    with col3:
        data_sources = st.multiselect("é€‰æ‹©æ•°æ®æº", ["Government", "Toutiao", "Weibo"], default=[])

    if not data_sources:
        st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ•°æ®æºã€‚")
    else:
        df = get_document_count_by_period_and_source(selected_category, selected_label, data_sources)

        if not df.empty:
            df['Period'] = df['Year'].astype(str) + " " + df['Half']
            # st.dataframe(df)
            fig = px.bar(df, x='Period', y='DocumentCount', color='Source', title='ä¸»é¢˜è¶‹åŠ¿ï¼ˆåŠå¹´ç²’åº¦ï¼‰', barmode='stack')
            st.plotly_chart(fig)
        else:
            st.write("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®")

st.markdown("---")
# ä½¿ç”¨containerå®¹å™¨ç»„ç»‡åœ°åŒºä¸»é¢˜åå¥½éƒ¨åˆ†
# ä½¿ç”¨@st.cache_dataè£…é¥°å™¨ç¼“å­˜è·å–çœä»½ä¿¡æ¯çš„å‡½æ•°

@st.cache_data
def execute_query(query, params=None):
    with engine.connect() as conn:
        if params:
            return pd.read_sql_query(text(query), conn, params=params)
        else:
            return pd.read_sql_query(text(query), conn)

@st.cache_data
def get_categories():
    query = "SELECT DISTINCT Category FROM Topics"
    return ['å…¨éƒ¨'] + pd.read_sql(query, engine)['Category'].tolist()

def get_labels(category=None):
    if category and category != 'å…¨éƒ¨':
        query = "SELECT DISTINCT Label FROM Topics WHERE Category = :category"
        with engine.connect() as conn:
            result = conn.execute(text(query), {'category': category})
            labels = [row['Label'] for row in result.mappings()]
    else:
        query = "SELECT DISTINCT Label FROM Topics"
        with engine.connect() as conn:
            result = conn.execute(text(query))
            labels = [row['Label'] for row in result.mappings()]
    return labels
@st.cache_data
def get_province_preference_data(data_sources, selected_years, selected_category, selected_label):
    query_params = {
        "start_year": selected_years[0],
        "end_year": selected_years[1],
        "category": selected_category,
        "label": selected_label
    }

    queries = []
    for source in data_sources:
        table_name = f"{source}Articles"
        assoc_table_name = f"{source}ArticleTopicAssociation"
        sub_query = f"""
        SELECT a.Province, COUNT(*) AS DocumentCount
        FROM {table_name} AS a
        JOIN {assoc_table_name} AS ata ON a.ArticleID = ata.ArticleID
        JOIN Topics AS t ON ata.TopicID = t.TopicID
        WHERE YEAR(a.PubDate) BETWEEN :start_year AND :end_year
        """
        if selected_category != 'å…¨éƒ¨':
            sub_query += " AND t.Category = :category"
        if selected_label != 'å…¨éƒ¨':
            sub_query += " AND t.Label = :label"
        sub_query += " GROUP BY a.Province"
        queries.append(sub_query)

    combined_query = " UNION ALL ".join(queries)
    return execute_query(combined_query, query_params)


# ä½¿ç”¨containerå®¹å™¨ç»„ç»‡åœ°åŒºä¸»é¢˜åå¥½åˆ†æéƒ¨åˆ†
with st.container():
    st.header("åœ°åŒºä¸»é¢˜åå¥½")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        categories = get_categories()
        selected_category = st.selectbox("é€‰æ‹©ä¸»é¢˜ç±»åˆ«", categories, key="category_preference")

    with col2:
        labels = get_labels(selected_category)
        selected_label = st.selectbox("é€‰æ‹©ä¸»é¢˜", labels, key="label_preference")

    with col3:
        data_sources = st.multiselect("é€‰æ‹©æ•°æ®æº", ["Government", "Toutiao", "Weibo"], default=[],
                                      key="data_source_preference")

    with col4:
        selected_years = st.slider("é€‰æ‹©å¹´ä»½èŒƒå›´", 2019, 2023, (2019, 2023), key="year_range_preference")

    if data_sources and selected_years and (selected_category != 'å…¨éƒ¨' or selected_label != 'å…¨éƒ¨'):
        df_province_preference = get_province_preference_data(data_sources, selected_years, selected_category,
                                                       selected_label)
        # st.dataframe(df_province_preference)
        with st.container():
            col1, col2 = st.columns([3, 1])  # åˆ†å‰²å±å¹•ç©ºé—´ï¼Œçƒ­åŠ›å›¾å 3/4ï¼Œé¥¼å›¾åŠç­›é€‰å™¨å 1/4
            with col1:
                df_location = pd.read_csv('locations.csv')

                # å°†çœä»½åç§°è½¬æ¢ä¸ºä½ çš„æ•°æ®ä¸­ç›¸å¯¹åº”çš„åç§°
                df_location.rename(columns={'çœä»½': 'Province', 'ç»åº¦': 'Longitude', 'ç»´åº¦': 'Latitude'}, inplace=True)

                # åˆå¹¶åå¥½æ•°æ®å’Œåœ°ç†ä½ç½®ä¿¡æ¯
                df_merged = pd.merge(df_province_preference, df_location, on='Province')

                # åˆ›å»ºåœ°å›¾ï¼Œä¸­å¿ƒè®¾ç½®ä¸ºä¸­å›½ï¼Œç¼©æ”¾çº§åˆ«è°ƒæ•´ä»¥è¦†ç›–æ•´ä¸ªä¸­å›½
                m = folium.Map(location=[35, 105], zoom_start=3.3)

                # æ·»åŠ çƒ­åŠ›å›¾å±‚ï¼Œè°ƒæ•´å‚æ•°ä»¥ä¼˜åŒ–å¤–è§‚
                HeatMap(data=df_merged[['Latitude', 'Longitude', 'DocumentCount']], radius=20).add_to(m)

                # ä½¿ç”¨CircleMarkerä»£æ›¿Markerï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´radiusæ¥æ”¹å˜å¤§å°
                for i, row in df_merged.iterrows():
                    folium.CircleMarker(
                        location=[row['Latitude'], row['Longitude']],
                        radius=2,  # æ§åˆ¶åœ†ç‚¹å¤§å°
                        popup=f"{row['Province']}: {row['DocumentCount']} documents",
                        fill=True,
                        color='blue',
                        fillColor='blue',
                        fillOpacity=0.6
                    ).add_to(m)

                # åœ¨Streamlitä¸­æ˜¾ç¤ºåœ°å›¾
                map_html = m._repr_html_()
                components.html(map_html, height=400, width=500)

            # çœä»½ä¸»é¢˜åå¥½
            with col2:
                # ä¸‹æ‹‰åˆ—è¡¨ç­›é€‰å™¨
                provinces = get_provinces()
                # çœä»½é€‰æ‹©ä¸‹æ‹‰ç­›é€‰å™¨
                selected_province = st.selectbox('é€‰æ‹©åœ°åŒº', provinces, index=0, key='province_select')

                # æ ¹æ®é€‰æ‹©çš„çœä»½è¿›è¡Œè”è¡¨æŸ¥è¯¢
                if selected_province == 'å…¨éƒ¨':
                    query = """
                        SELECT Category, COUNT(*) AS Count
                        FROM Topics
                        GROUP BY Category
                        """
                else:
                    query = f"""
                        SELECT Category, COUNT(*) AS Count
                        FROM Topics
                        WHERE Province = '{selected_province}'
                        GROUP BY Category
                        """

                df = pd.read_sql_query(query, engine)
                # st.dataframe(df)
                # åˆ›å»ºé¥¼å›¾
                fig_pie = px.pie(df, values='Count', names='Category', title='çœä»½ä¸»é¢˜åå¥½')
                fig_pie.update_traces(textinfo='none', hoverinfo='label+percent',
                                      marker=dict(line=dict(color='#000000', width=2)))
                fig_pie.update_layout(height=300, showlegend=True)

                # å±•ç¤ºé¥¼å›¾
                st.plotly_chart(fig_pie, use_container_width=True)  # ä½¿ç”¨å®¹å™¨å®½åº¦
    else:
        st.error("è¯·ç¡®ä¿é€‰æ‹©äº†æ•°æ®æºå¹¶ä¸”è‡³å°‘é€‰æ‹©äº†ä¸€ä¸ªä¸»é¢˜ç±»åˆ«æˆ–ä¸»é¢˜ã€‚")

